{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yjoAV7VV1Hqv"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "groups = fetch_20newsgroups()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = fetch_20newsgroups(subset='train', random_state=21)\n",
        "train_label = data_train.target\n",
        "data_test = fetch_20newsgroups(subset='test', random_state=21)\n",
        "test_label = data_test.target\n",
        "len(data_train.data), len(data_test.data), len(test_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CPWxILn1Q40",
        "outputId": "dcf1aa0f-ce03-4184-fc01-7182480ecae8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 7532, 7532)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il y a 20 classes différentes :"
      ],
      "metadata": {
        "id": "_QLdMAp_clft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.unique(test_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bN05NHby1SCR",
        "outputId": "e55581ae-c0b3-4c18-837d-b9bd5aa4cd70"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "       17, 18, 19])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Nettoyage du corpus et réduction du bruit dans ce dernier**\n",
        "\n",
        "On filtre les éléments dans le corpus avec 2 conditions :\n",
        "\n",
        "#### **1. Suppression des entités nommées**\n",
        "\n",
        "Les prénoms peuvent introduire du bruit et biaiser l'apprentissage du modèle. Pour retirer les prénoms, on utilise le corpus NLTK qui contient de très nombreux noms en anglais. Ensuite on retire les noms dans la boucle, en utilisant `words not in all_names`.\n",
        "\n",
        "#### **2. Suppression des caractères spéciaux**\n",
        "\n",
        "On élimine la ponctuation (ex: \"!\", \"?\", \".\") et les nombres avec `words.isalpha()`.\n",
        "\n",
        "\n",
        "#### **Normalisation et lemmatisation**\n",
        "\n",
        "Si un mot satisfait ces deux conditions, on applique `words.lower()` qui transforme le mot en minuscules et on réduit le mot à sa forme de base (lemme) avec `WNL.lemmatize(...)` . Cela réduit la dimensionalité du vocabulaire"
      ],
      "metadata": {
        "id": "dw6aoQZZrv7P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('names')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aiSha0irl8E",
        "outputId": "20b53086-34e9-428f-964d-e4161727b2db"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package names to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/names.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from multiprocessing import Pool, cpu_count\n",
        "from functools import partial\n",
        "\n",
        "def init_worker():\n",
        "    global names_set, wnl\n",
        "    from nltk.corpus import names\n",
        "    from nltk.stem import WordNetLemmatizer\n",
        "    names_set = {n.lower() for n in names.words()}\n",
        "    wnl = WordNetLemmatizer()\n",
        "\n",
        "def clean_text(text):\n",
        "    global names_set, wnl\n",
        "    # Regex\n",
        "    tokens = re.findall(r'[a-z]{3,}', text.lower())\n",
        "    words = [wnl.lemmatize(w) for w in tokens if w not in names_set]\n",
        "    return \" \".join(words)\n",
        "\n",
        "def clean(data):\n",
        "    with Pool(cpu_count(), initializer=init_worker) as pool:\n",
        "        return pool.map(clean_text, data, chunksize=100)"
      ],
      "metadata": {
        "id": "UcbkH5u8zaQj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = clean(data_test.data)\n",
        "x_train = clean(data_train.data)\n",
        "len(x_test)\n",
        "len(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3q6hOru1prE",
        "outputId": "cb579ab7-725d-42d8-ed7b-e277d9970189"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11314"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SVM linéaire**\n",
        "\n",
        "\n",
        "On distingue deux grands types de SVM linéaires : le **Hard margin** SVM et le **Soft margin** SVM.\n",
        "\n",
        "### SVM **Hard Margin**\n",
        "\n",
        "Dans le premier, les instances doivent être parfaitement séparables par un hyperplan linéaire.\n",
        "\n",
        "Pour les points $x_i$ dans la classe $y_i = 1$ on impose :\n",
        "$$\\omega^\\top x_i + b \\ge 1$$\n",
        "\n",
        "Pour les points $x_i$ dans la classe $y_i = -1$ on impose :\n",
        "$$\\omega^\\top x_i + b \\le -1$$\n",
        "\n",
        "On constate qu'un élément $x_i$ est bien classifié si $y_i$ et $(\\omega^\\top x_i + b)$ ont le même signe. Ainsi, on peut reformuler ces deux contraintes de manière unifiée :\n",
        "$$\\boxed{\\forall i,\\quad y_i \\cdot (\\omega^\\top x_i + b) \\ge 1}$$\n",
        "\n",
        "\n",
        "Mais cela suppose que les données soient parfaitement linéairement séparables.\n",
        "\n",
        "Si ce n'est pas le cas, alors, quel que soit l’hyperplan choisi, il existera au moins un point $x_i$ pour lequel $y_i \\cdot (\\omega^\\top x_i + b) \\le 0$ c’est-à-dire au moins un point mal classé (ce qui arrive si $y_i$ et $(\\omega^\\top x_i + b)$ ont des signes différents), ou situé sur la frontière de décision (ce qui arrive si $y_i \\cdot (\\omega^\\top x_i + b) = 0$).\n",
        "\n",
        "Formellement, c'est linéairement séparable si\n",
        "\n",
        "$$\\exists (\\omega,b)\\ \\text{tel que}\\ \\forall i,\\ y_i(\\omega^\\top x_i + b) > 0$$\n",
        "\n",
        "\n",
        "et non linéairement séparable si :\n",
        "\n",
        "$$\\forall (\\omega,b),\\ \\exists i\\ \\text{tel que}\\ y_i(\\omega^\\top x_i + b) \\le 0$$\n",
        "\n",
        "### SVM **Soft Margin**\n",
        "\n",
        "C'est ce pourquoi on utilise un **SVM linéaire soft margin** qui fonctionne même si les données ne sont pas parfaitement linéairement séparables en tolérant des écarts et donc des erreurs de classifications éventuelles.\n",
        "\n",
        "De manière générale, dans un SVM, il faut maximiser l'espacement entre les deux marges (qui correspondent aux deux hyperplans $\\{ x \\in \\mathbb{R}^d \\;|\\; \\omega^\\top x + b = 1 \\}$ et $\\{ x \\in \\mathbb{R}^d \\;|\\; \\omega^\\top x + b = -1 \\}$). Mais, avec certaines données non linéairement séparables, il faut trouver un compromis entre la largeur de la marge et les erreurs de classification.\n",
        "\n",
        "Dans un SVM soft margin, on associe à chaque point $x_i$ une quantité $\\xi_i$ qui indique “de combien il manque” pour satisfaire la condition idéale $y_i(\\omega^\\top x_i + b) \\ge 1$. Pour chaque point $x_i$, la quantité $\\xi_i$ est donnée par :\n",
        "\n",
        "$$\\xi_i = \\max(0, 1 - y_i (\\omega^\\top x_i + b))$$\n",
        "\n",
        "Il y a trois cas possibles (bien classé, dans la marge, mal classé) :\n",
        "\n",
        "* Si le point $x_i$ est bien classé :\n",
        "\n",
        "$$\n",
        "y_i (\\omega^\\top x_i + b) \\ge 1\n",
        "\\quad\\Rightarrow\\quad\n",
        "\\big[1 - y_i (\\omega^\\top x_i + b)\\big] \\le 0\n",
        "\\quad\\Rightarrow\\quad\n",
        "\\xi_i = 0\n",
        "$$\n",
        "\n",
        "* Si le point $x_i$ est dans la marge (entre les deux hyperplans) mais correctement classé :\n",
        "\n",
        "$$\n",
        "0 < y_i (\\omega^\\top x_i + b) < 1\n",
        "\\quad\\Rightarrow\\quad\n",
        "0 < \\xi_i = \\big[1 - y_i (\\omega^\\top x_i + b)\\big] < 1\n",
        "$$\n",
        "\n",
        "* Si le point $x_i$ est mal classé :\n",
        "\n",
        "$$\n",
        "y_i (\\omega^\\top x_i + b) < 0\n",
        "\\quad\\Rightarrow\\quad\n",
        "\\xi_i = \\big[1 - y_i (\\omega^\\top x_i + b)\\big] > 1\n",
        "$$\n",
        "\n",
        "Maintenant, on peut pénaliser le modèle à la fois en fonction du nombre de points du mauvais côté (en comptant à la fois les points dans les marges bien classés et ceux qui sont mal classés) et de l'ampleur des violations (plus la position d'un point s'écarte de sa position attendue, plus la pénalité sur la loss sera forte)."
      ],
      "metadata": {
        "id": "6Eb4EwsVt91X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Comparaison de [`LinearSVC`]( https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html) et de [`SGDClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html)**\n",
        "\n",
        "Dans `LinearSVC` de Scikitlearn, on peut régler le compromis entre la largeur de la marge et les erreurs sur l’échantillon grâce à l'hyperparamètre $C$.\n",
        "\n",
        "Si $C$ est grand, on cherche à réduire au maximum ces erreurs quitte à avoir une marge plus petite ; si $C$ est petit, on tolère davantage les violations pour favoriser une marge plus large.\n",
        "\n",
        "Sur `SGDClassifier` l'hyperparamètre \"alpha\" joue un rôle équivalent\n",
        "\n",
        "SGDClassifier avec loss='hinge' = SVM linéaire\n",
        "\n"
      ],
      "metadata": {
        "id": "wzgys3di32nL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Le choix de l'optimiseur d'hyperparamètres : GridSearch ou Optuna ?**\n",
        "\n",
        "\n",
        "### **GridSearch**\n",
        "**[`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)** effectue une recherche ***exhaustive*** : il teste *toutes* les combinaisons possibles dans des grilles d'hyperparamètres prédéfinies.\n",
        "Bien qu'on ait la garantie de trouver l'optimum global dans l'espace discret prédéfini, le temps et le coût computationnel peuvent vite devenir très élevés en fonction de la taille de l'espace des valeurs possibles.\n",
        "\n",
        "\n",
        "### **Optuna**\n",
        "**[`Optuna`](https://pypi.org/project/optuna/)** utilise une recherche ***bayésienne*** (algorithme TPE - Tree-structured Parzen Estimator) en échantillonnant l'espace des hyperparamètres et en privilégiant les régions prometteuses identifiées par les évaluations précédentes. Cela permet d'obtenir de bonnes solutions avec moins d'itérations. C'est pas absolument nécessaire ici mais dans certains cas où les espaces d'hyperparamètres à tester sont de très grande dimension et continus c'est plus rapide et efficace."
      ],
      "metadata": {
        "id": "OUPhMkfVSDTE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### **Suppression des stop-words**\n",
        "\n",
        "Scikit-learn possède un fichier interne qui contient une liste fixe de mots anglais considérés comme des `stop_words` . Comme ils le font dans les codes proposé sur leur site (par exemple [ce code](https://scikit-learn.org/stable/auto_examples/text/plot_document_classification_20newsgroups.html) ou encore [ce code](https://scikit-learn.org/0.21/auto_examples/text/plot_document_classification_20newsgroups.html)), on enlève les `stop_words` présents dans le corpus. On peut afficher le nombre de ces `stop_words` et les inspecter manuellement avec :\n",
        "\n",
        "```python\n",
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
        "print(len(ENGLISH_STOP_WORDS))\n",
        "print(list(ENGLISH_STOP_WORDS))\n",
        "```"
      ],
      "metadata": {
        "id": "YNjzBoaTOOm3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Méthodologie\n",
        "\n",
        "Puisqu'on ne sait pas trop quoi choisir entre [`LinearSVC`]( https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html) et  [`SGDClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html), nous allons tester une optimisation des hyperparamètres avec les deux\n",
        "\n",
        "Pour que ce soit vraiment comparable, on va essayer de faire vraiment l'équivalent des deux côtés."
      ],
      "metadata": {
        "id": "X53wqBCzAxk5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Commençons par computer toutes les matrices TF-IDF qui vont être utilisées, de manière à éviter de les re-calculer. La cellule qui suit prend quelques minutes à s'executer et prend un certain espace dans la RAM, mais elle permettra de gagner du temps lors des étapes qui suivent."
      ],
      "metadata": {
        "id": "qruTR2qUDkFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from joblib import Parallel, delayed\n",
        "from itertools import product\n",
        "import numpy as np\n",
        "\n",
        "# Valeurs discrètes pour le cache (step=4000 pour max_features)\n",
        "MAX_FEATURES_VALUES = [10000, 15000, 20000, 25000, 30000]\n",
        "MAX_DF_VALUES = [0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
        "\n",
        "def precompute_tfidf(texts_train, texts_test, max_feats, max_df_vals, n_jobs=-1):\n",
        "    \"\"\"\n",
        "    Pré-calcule les matrices TF-IDF pour toutes les combinaisons d'hyperparamètres.\n",
        "    Stocke aussi le vectorizer pour transformer les données de test.\n",
        "    \"\"\"\n",
        "    def fit(mf, mdf):\n",
        "        vec = TfidfVectorizer(\n",
        "            stop_words=\"english\",\n",
        "            ngram_range=(1, 2),\n",
        "            max_features=mf,\n",
        "            max_df=mdf,\n",
        "            dtype=np.float32\n",
        "        )\n",
        "        X_train = vec.fit_transform(texts_train)\n",
        "        X_test = vec.transform(texts_test)\n",
        "        return (mf, mdf), {\n",
        "            'vectorizer': vec,\n",
        "            'X_train': X_train,\n",
        "            'X_test': X_test\n",
        "        }\n",
        "\n",
        "    results = Parallel(n_jobs=n_jobs)(\n",
        "        delayed(fit)(mf, mdf)\n",
        "        for mf, mdf in product(max_feats, max_df_vals)\n",
        "    )\n",
        "    return dict(results)\n",
        "\n",
        "# Pré-calcul (exécuté une seule fois)\n",
        "print(f\"Pré-calcul de {len(MAX_FEATURES_VALUES) * len(MAX_DF_VALUES)} matrices TF-IDF...\")\n",
        "tfidf_cache = precompute_tfidf(\n",
        "    x_train, x_test,\n",
        "    MAX_FEATURES_VALUES,\n",
        "    MAX_DF_VALUES\n",
        ")\n",
        "print(f\"Cache créé avec {len(tfidf_cache)} entrées.\")"
      ],
      "metadata": {
        "id": "rHTV2MJdDVKC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d5f7216-c4f6-4244-c8d9-9fcbaad9fb77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pré-calcul de 30 matrices TF-IDF...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install optuna -q"
      ],
      "metadata": {
        "id": "wR5h8gfcujNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import optuna\n",
        "import time\n",
        "\n",
        "def create_objective_fast_cached(y, tfidf_cache, cv=3):\n",
        "    \"\"\"Objective utilisant le cache TF-IDF pré-calculé.\"\"\"\n",
        "    def objective(trial):\n",
        "        # Utiliser suggest_categorical pour correspondre exactement au cache\n",
        "        max_features = trial.suggest_categorical('max_features', MAX_FEATURES_VALUES)\n",
        "        max_df = trial.suggest_categorical('max_df', MAX_DF_VALUES)\n",
        "        alpha = trial.suggest_float('alpha', 1e-4, 1e-2, log=True)\n",
        "\n",
        "        # Récupération de la matrice pré-calculée (économie de compute !)\n",
        "        X_tfidf = tfidf_cache[(max_features, max_df)]['X_train']\n",
        "\n",
        "        clf = SGDClassifier(\n",
        "            loss='hinge',\n",
        "            alpha=alpha,\n",
        "            max_iter=1000,\n",
        "            tol=1e-3,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        # Mesure du temps d'exécution\n",
        "        t0 = time.perf_counter()\n",
        "        score = cross_val_score(clf, X_tfidf, y, cv=cv, n_jobs=-1).mean()\n",
        "        trial.set_user_attr(\"duration\", time.perf_counter() - t0)\n",
        "\n",
        "        return score\n",
        "\n",
        "    return objective\n",
        "\n",
        "def run_optuna_fast_cached(y, tfidf_cache, n_trials=30, cv=3):\n",
        "    study = optuna.create_study(\n",
        "        direction='maximize',\n",
        "        sampler=optuna.samplers.TPESampler(seed=42),\n",
        "        pruner=optuna.pruners.MedianPruner(n_startup_trials=5)\n",
        "    )\n",
        "    objective = create_objective_fast_cached(y, tfidf_cache, cv)\n",
        "    study.optimize(objective, n_trials=n_trials, n_jobs=1, show_progress_bar=True)\n",
        "    return study\n",
        "\n",
        "# Lancement\n",
        "study_sgd = run_optuna_fast_cached(train_label, tfidf_cache, n_trials=30)\n",
        "\n",
        "print(f\"\\n[SGDClassifier] Meilleurs paramètres : {study_sgd.best_params}\")\n",
        "print(f\"[SGDClassifier] Meilleur score CV : {study_sgd.best_value:.4f}\")"
      ],
      "metadata": {
        "id": "fhzmzCsC0EpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On utilise un système de pruning `pruner=optuna.pruners.MedianPruner(n_startup_trials=5)`"
      ],
      "metadata": {
        "id": "w3Y7U1s5Uzjh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il y a une formule qui permet de trouver les équivalences entre $C$ et $alpha$ (voir https://scikit-learn.org/stable/modules/linear_model.html#comparison-with-the-regularization-parameter-of-svm )"
      ],
      "metadata": {
        "id": "VV5xJF6QFl-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code de calcul des bornes\n",
        "n_samples = len(x_test)\n",
        "alpha_min = 1e-4\n",
        "alpha_max = 1e-2\n",
        "\n",
        "# Application de la formule\n",
        "c_max_equivalent = 1 / (n_samples * alpha_min)\n",
        "c_min_equivalent = 1 / (n_samples * alpha_max)\n",
        "\n",
        "print(f\"Pour alpha={alpha_max} C équivalent ≈ {c_min_equivalent:.5f}\")\n",
        "print(f\"Pour alpha={alpha_min} C équivalent ≈ {c_max_equivalent:.5f}\")"
      ],
      "metadata": {
        "id": "JGNrl0GK_pbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import optuna\n",
        "import optuna.visualization.matplotlib as vis_mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "def create_objective_large_cached(y, tfidf_cache, cv=3):\n",
        "    \"\"\"Objective utilisant le cache TF-IDF pré-calculé.\"\"\"\n",
        "    def objective(trial):\n",
        "        max_features = trial.suggest_categorical('max_features', MAX_FEATURES_VALUES)\n",
        "        max_df = trial.suggest_categorical('max_df', MAX_DF_VALUES)\n",
        "        C = trial.suggest_float('C', 0.1, 1.3, log=True)\n",
        "\n",
        "        # Récupération de la matrice pré-calculée\n",
        "        X_tfidf = tfidf_cache[(max_features, max_df)]['X_train']\n",
        "\n",
        "        clf = LinearSVC(C=C, dual=True, max_iter=2000, random_state=42)\n",
        "\n",
        "        # Mesure du temps\n",
        "        t0 = time.perf_counter()\n",
        "        score = cross_val_score(clf, X_tfidf, y, cv=cv, n_jobs=-1).mean()\n",
        "        trial.set_user_attr(\"duration\", time.perf_counter() - t0)\n",
        "\n",
        "        return score\n",
        "\n",
        "    return objective\n",
        "\n",
        "def run_optuna_large_cached(y, tfidf_cache, n_trials=40, cv=3):\n",
        "    study = optuna.create_study(direction='maximize')\n",
        "    objective = create_objective_large_cached(y, tfidf_cache, cv)\n",
        "    study.optimize(objective, n_trials=n_trials, n_jobs=-1, show_progress_bar=True)\n",
        "    return study\n",
        "\n",
        "# Lancement\n",
        "study_large = run_optuna_large_cached(train_label, tfidf_cache, n_trials=40)\n",
        "\n",
        "print(f\"\\n[LinearSVC] Meilleurs paramètres : {study_large.best_params}\")\n",
        "print(f\"[LinearSVC] Meilleur score CV : {study_large.best_value:.4f}\")\n",
        "\n",
        "# Visualisations\n",
        "vis_mpl.plot_param_importances(study_large)\n",
        "plt.show()\n",
        "\n",
        "vis_mpl.plot_optimization_history(study_large)\n",
        "plt.show()\n",
        "\n",
        "vis_mpl.plot_slice(study_large, params=[\"max_features\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tZbai0QN-UlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Quel paramètre influence le plus le temps d'execution ?**"
      ],
      "metadata": {
        "id": "PuVV6t6Lj1_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import polars as pl\n",
        "\n",
        "def analyze_duration_importance(study, features, name):\n",
        "    \"\"\"Analyse l'importance des features sur le temps d'exécution.\"\"\"\n",
        "    df = pl.DataFrame([\n",
        "        t.params | {'duration': t.user_attrs['duration']}\n",
        "        for t in study.trials if t.state.name == \"COMPLETE\"\n",
        "    ])\n",
        "\n",
        "    rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "    rf.fit(df[features], df[\"duration\"])\n",
        "\n",
        "    importance = sorted(\n",
        "        zip(features, rf.feature_importances_.tolist()),\n",
        "        key=lambda x: x[1],\n",
        "        reverse=True\n",
        "    )\n",
        "    print(f\"\\n{name} - Importance des features sur le temps d'exécution:\")\n",
        "    for feat, imp in importance:\n",
        "        print(f\"  {feat}: {imp:.4f}\")\n",
        "    return importance\n",
        "\n",
        "# Analyse pour les deux études\n",
        "analyze_duration_importance(study_sgd, [\"max_features\", \"max_df\", \"alpha\"], \"SGDClassifier\")\n",
        "analyze_duration_importance(study_large, [\"max_features\", \"max_df\", \"C\"], \"LinearSVC\")"
      ],
      "metadata": {
        "id": "pMHGAlmei2el"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Résultats**\n",
        "\n",
        "Le troisième graphique suggère que plus la dimensionalité des vecteurs TF-IDF est grande (plus l'hyperparamètre `max_features` est élevé), plus la performance est élevée"
      ],
      "metadata": {
        "id": "-03VTpvrYQre"
      }
    }
  ]
}